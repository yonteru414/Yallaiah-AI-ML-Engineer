<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LangChain Learning Path</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
    <style>
        :root {
            --primary-bg: #0a0a0a;
            --secondary-bg: #1a1a1a;
            --card-bg: #222222;
            --accent-color: #4361ee;
            --accent-hover: #3a56d4;
            --text-primary: #ffffff;
            --text-secondary: #b8b8b8;
            --code-bg: #1e1e1e;
            --border-color: #333333;
            --success-color: #28a745;
            --warning-color: #ffc107;
            --info-color: #17a2b8;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background-color: var(--primary-bg);
            color: var(--text-primary);
            line-height: 1.6;
            overflow-x: hidden;
        }

        /* Header Styles */
        .main-header {
            background-color: var(--secondary-bg);
            padding: 1.5rem 0;
            border-bottom: 1px solid var(--border-color);
            position: sticky;
            top: 0;
            z-index: 100;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.5);
        }

        .header-content {
            display: flex;
            justify-content: space-between;
            align-items: center;
            max-width: 1400px;
            margin: 0 auto;
            padding: 0 2rem;
        }

        .logo {
            display: flex;
            align-items: center;
            gap: 0.75rem;
        }

        .logo-icon {
            width: 40px;
            height: 40px;
            background: linear-gradient(135deg, var(--accent-color), #7209b7);
            border-radius: 8px;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-size: 1.5rem;
        }

        .logo h1 {
            font-size: 1.8rem;
            font-weight: 700;
            background: linear-gradient(90deg, var(--accent-color), #7209b7);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .back-btn {
            background-color: var(--card-bg);
            border: 1px solid var(--border-color);
            color: var(--text-primary);
            padding: 0.5rem 1.25rem;
            border-radius: 6px;
            text-decoration: none;
            display: flex;
            align-items: center;
            gap: 0.5rem;
            transition: all 0.3s ease;
        }

        .back-btn:hover {
            background-color: var(--accent-color);
            border-color: var(--accent-color);
            color: white;
            transform: translateY(-2px);
        }

        /* Navigation Grid */
        .nav-container {
            max-width: 1400px;
            margin: 3rem auto;
            padding: 0 2rem;
        }

        .nav-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 1.5rem;
        }

        .nav-card {
            background-color: var(--card-bg);
            border: 1px solid var(--border-color);
            border-radius: 12px;
            padding: 1.5rem;
            text-align: center;
            transition: all 0.3s ease;
            cursor: pointer;
            position: relative;
            overflow: hidden;
        }

        .nav-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 4px;
            background: linear-gradient(90deg, var(--accent-color), #7209b7);
            transform: scaleX(0);
            transition: transform 0.3s ease;
        }

        .nav-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.3);
            border-color: var(--accent-color);
        }

        .nav-card:hover::before {
            transform: scaleX(1);
        }

        .nav-card.active {
            border-color: var(--accent-color);
            background-color: rgba(67, 97, 238, 0.1);
        }

        .nav-card.active::before {
            transform: scaleX(1);
        }

        .nav-icon {
            font-size: 2.5rem;
            margin-bottom: 1rem;
            color: var(--accent-color);
        }

        .nav-title {
            font-size: 1.2rem;
            font-weight: 600;
            margin-bottom: 0.5rem;
        }

        .nav-desc {
            font-size: 0.9rem;
            color: var(--text-secondary);
            line-height: 1.4;
        }

        /* Content Section */
        .content-container {
            max-width: 1200px;
            margin: 0 auto 4rem;
            padding: 0 2rem;
        }

        .content-section {
            display: none;
            animation: fadeIn 0.5s ease-in-out;
        }

        .content-section.active {
            display: block;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .section-header {
            background: linear-gradient(135deg, var(--card-bg), var(--secondary-bg));
            border: 1px solid var(--border-color);
            border-radius: 12px;
            padding: 2rem;
            margin-bottom: 2rem;
            text-align: center;
        }

        .section-title {
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 1rem;
            background: linear-gradient(90deg, var(--accent-color), #7209b7);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .section-subtitle {
            font-size: 1.2rem;
            color: var(--text-secondary);
            margin-bottom: 1.5rem;
        }

        /* Module Cards */
        .modules-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 2rem;
            margin-bottom: 3rem;
        }

        .module-card {
            background-color: var(--card-bg);
            border: 1px solid var(--border-color);
            border-radius: 12px;
            padding: 2rem;
            transition: all 0.3s ease;
        }

        .module-card:hover {
            transform: translateY(-3px);
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.3);
            border-color: var(--accent-color);
        }

        .module-header {
            display: flex;
            align-items: center;
            gap: 1rem;
            margin-bottom: 1.5rem;
        }

        .module-icon {
            width: 50px;
            height: 50px;
            background: linear-gradient(135deg, var(--accent-color), #7209b7);
            border-radius: 10px;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-size: 1.5rem;
        }

        .module-title {
            font-size: 1.5rem;
            font-weight: 600;
            color: var(--text-primary);
        }

        .module-description {
            color: var(--text-secondary);
            margin-bottom: 1.5rem;
            line-height: 1.6;
        }

        .topics-list {
            list-style: none;
            margin-bottom: 1.5rem;
        }

        .topics-list li {
            padding: 0.5rem 0;
            border-bottom: 1px solid var(--border-color);
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .topics-list li:last-child {
            border-bottom: none;
        }

        .topic-name {
            color: var(--text-primary);
        }

        .learn-more-btn {
            background-color: var(--accent-color);
            color: white;
            border: none;
            padding: 0.3rem 0.8rem;
            border-radius: 6px;
            font-size: 0.8rem;
            text-decoration: none;
            transition: all 0.3s ease;
            display: inline-block;
        }

        .learn-more-btn:hover {
            background-color: var(--accent-hover);
            color: white;
            transform: scale(1.05);
        }

        /* Code Blocks - Enhanced for better readability */
        .code-example {
            background-color: var(--code-bg);
            border: 1px solid var(--border-color);
            border-radius: 12px;
            margin: 2rem 0;
            overflow: hidden;
        }

        .code-header {
            background-color: var(--secondary-bg);
            padding: 1rem 1.5rem;
            border-bottom: 1px solid var(--border-color);
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .code-title {
            font-weight: 600;
            color: var(--text-primary);
        }

        .copy-btn {
            background-color: var(--accent-color);
            color: white;
            border: none;
            padding: 0.4rem 0.8rem;
            border-radius: 6px;
            font-size: 0.8rem;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .copy-btn:hover {
            background-color: var(--accent-hover);
        }

        .code-content {
            padding: 2rem;
            font-family: 'Courier New', monospace;
            font-size: 1rem;
            line-height: 1.8;
            color: var(--text-primary);
            overflow-x: auto;
        }

        .code-content pre {
            margin: 0;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        /* Progress Indicators */
        .progress-section {
            background-color: var(--card-bg);
            border: 1px solid var(--border-color);
            border-radius: 12px;
            padding: 1.5rem;
            margin-bottom: 2rem;
        }

        .progress-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 1rem;
        }

        .progress-title {
            font-size: 1.2rem;
            font-weight: 600;
        }

        .progress-percentage {
            color: var(--accent-color);
            font-weight: 600;
        }

        .progress-bar {
            height: 8px;
            background-color: var(--border-color);
            border-radius: 4px;
            overflow: hidden;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, var(--accent-color), #7209b7);
            transition: width 0.3s ease;
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            .header-content {
                padding: 0 1rem;
            }

            .nav-container, .content-container {
                padding: 0 1rem;
            }

            .nav-grid {
                grid-template-columns: 1fr;
            }

            .modules-grid {
                grid-template-columns: 1fr;
            }

            .section-title {
                font-size: 2rem;
            }

            .code-content {
                padding: 1rem;
                font-size: 0.9rem;
            }
        }

        /* Utility Classes */
        .text-accent { color: var(--accent-color); }
        .text-success { color: var(--success-color); }
        .text-warning { color: var(--warning-color); }
        .text-info { color: var(--info-color); }
    </style>
</head>
<body>
    <!-- Header -->
    <header class="main-header">
        <div class="header-content">
            <div class="logo">
                <div class="logo-icon">
                    <i class="fas fa-link"></i>
                </div>
                <h1>LangChain Mastery</h1>
            </div>
            <a href="#" class="back-btn">
                <i class="fas fa-home"></i>
                Back to Home
            </a>
        </div>
    </header>

    <!-- Navigation -->
    <div class="nav-container">
        <div class="nav-grid">
            <div class="nav-card active" data-section="beginner">
                <div class="nav-icon">
                    <i class="fas fa-seedling"></i>
                </div>
                <div class="nav-title">Beginner</div>
                <div class="nav-desc">Start your LangChain journey with fundamental concepts and basic implementations</div>
            </div>

            <div class="nav-card" data-section="intermediate">
                <div class="nav-icon">
                    <i class="fas fa-cogs"></i>
                </div>
                <div class="nav-title">Intermediate</div>
                <div class="nav-desc">Build more complex applications with chains, agents, and advanced features</div>
            </div>

            <div class="nav-card" data-section="advanced">
                <div class="nav-icon">
                    <i class="fas fa-rocket"></i>
                </div>
                <div class="nav-title">Advanced</div>
                <div class="nav-desc">Master production-ready deployments and optimization techniques</div>
            </div>

            <div class="nav-card" data-section="specialized">
                <div class="nav-icon">
                    <i class="fas fa-brain"></i>
                </div>
                <div class="nav-title">Specialized</div>
                <div class="nav-desc">Explore domain-specific applications and cutting-edge implementations</div>
            </div>
        </div>
    </div>

    <!-- Content Container -->
    <div class="content-container">
        <!-- Beginner Section -->
        <div class="content-section active" id="beginner">
            <div class="section-header">
                <h2 class="section-title">
                    <i class="fas fa-seedling text-accent"></i>
                    Beginner Level
                </h2>
                <p class="section-subtitle">Master the fundamentals of LangChain and build your first applications</p>
                <div class="progress-section">
                    <div class="progress-header">
                        <span class="progress-title">Overall Progress</span>
                        <span class="progress-percentage">0%</span>
                    </div>
                    <div class="progress-bar">
                        <div class="progress-fill" style="width: 0%"></div>
                    </div>
                </div>
            </div>

            <div class="modules-grid">
                <!-- Module 1: Introduction & Setup -->
                <div class="module-card">
                    <div class="module-header">
                        <div class="module-icon">
                            <i class="fas fa-play"></i>
                        </div>
                        <h3 class="module-title">Introduction & Setup</h3>
                    </div>
                    <p class="module-description">Get started with LangChain, understand its core concepts, and set up your development environment.</p>
                    
                    <ul class="topics-list">
                        <li>
                            <span class="topic-name">What is LangChain?</span>
                            <a href="/learn/beginner/what-is-langchain" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Installation & Setup</span>
                            <a href="/learn/beginner/installation-setup" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Core Components Overview</span>
                            <a href="/learn/beginner/core-components" class="learn-more-btn">Learn More</a>
                        </li>
                    </ul>

                    <div class="code-example">
                        <div class="code-header">
                            <span class="code-title">Quick Start Example</span>
                            <button class="copy-btn" onclick="copyCode(this)">
                                <i class="fas fa-copy"></i> Copy
                            </button>
                        </div>
                        <div class="code-content">
                            <pre># Install LangChain
pip install langchain openai

# Basic setup
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# Initialize LLM
llm = OpenAI(temperature=0.7)

# Create a prompt template
prompt = PromptTemplate(
    input_variables=["topic"],
    template="Write a brief explanation about {topic}:"
)

# Create and run chain
chain = LLMChain(llm=llm, prompt=prompt)
result = chain.run(topic="machine learning")
print(result)</pre>
                        </div>
                    </div>
                </div>

                <!-- Module 2: LLMs and Prompts -->
                <div class="module-card">
                    <div class="module-header">
                        <div class="module-icon">
                            <i class="fas fa-comment-dots"></i>
                        </div>
                        <h3 class="module-title">LLMs and Prompts</h3>
                    </div>
                    <p class="module-description">Learn how to work with different language models and create effective prompts for various tasks.</p>
                    
                    <ul class="topics-list">
                        <li>
                            <span class="topic-name">LLM Integration</span>
                            <a href="/learn/beginner/llm-integration" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Prompt Templates</span>
                            <a href="/learn/beginner/prompt-templates" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Few-shot Prompting</span>
                            <a href="/learn/beginner/few-shot-prompting" class="learn-more-btn">Learn More</a>
                        </li>
                    </ul>

                    <div class="code-example">
                        <div class="code-header">
                            <span class="code-title">Advanced Prompt Template</span>
                            <button class="copy-btn" onclick="copyCode(this)">
                                <i class="fas fa-copy"></i> Copy
                            </button>
                        </div>
                        <div class="code-content">
                            <pre>from langchain.prompts import PromptTemplate
from langchain.prompts.few_shot import FewShotPromptTemplate

# Define examples for few-shot learning
examples = [
    {
        "input": "What's 2+2?",
        "output": "The answer is 4."
    },
    {
        "input": "What's the capital of France?",
        "output": "The capital of France is Paris."
    }
]

# Create example template
example_template = """
Input: {input}
Output: {output}
"""

example_prompt = PromptTemplate(
    input_variables=["input", "output"],
    template=example_template
)

# Create few-shot prompt
few_shot_prompt = FewShotPromptTemplate(
    examples=examples,
    example_prompt=example_prompt,
    prefix="Answer the following questions:",
    suffix="Input: {input}\nOutput:",
    input_variables=["input"]
)

# Use the prompt
formatted_prompt = few_shot_prompt.format(
    input="What's the largest planet?"
)
print(formatted_prompt)</pre>
                        </div>
                    </div>
                </div>

                <!-- Module 3: Basic Chains -->
                <div class="module-card">
                    <div class="module-header">
                        <div class="module-icon">
                            <i class="fas fa-link"></i>
                        </div>
                        <h3 class="module-title">Basic Chains</h3>
                    </div>
                    <p class="module-description">Understand how to chain multiple components together to create more complex workflows.</p>
                    
                    <ul class="topics-list">
                        <li>
                            <span class="topic-name">LLMChain Basics</span>
                            <a href="/learn/beginner/llmchain-basics" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Sequential Chains</span>
                            <a href="/learn/beginner/sequential-chains" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Router Chains</span>
                            <a href="/learn/beginner/router-chains" class="learn-more-btn">Learn More</a>
                        </li>
                    </ul>

                    <div class="code-example">
                        <div class="code-header">
                            <span class="code-title">Sequential Chain Example</span>
                            <button class="copy-btn" onclick="copyCode(this)">
                                <i class="fas fa-copy"></i> Copy
                            </button>
                        </div>
                        <div class="code-content">
                            <pre>from langchain.chains import LLMChain, SimpleSequentialChain
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate

llm = OpenAI(temperature=0.7)

# First chain: Generate a topic
topic_template = """
You are a creative writer. Generate an interesting topic 
for a blog post about: {subject}
"""
topic_prompt = PromptTemplate(
    input_variables=["subject"],
    template=topic_template
)
topic_chain = LLMChain(llm=llm, prompt=topic_prompt)

# Second chain: Write content for the topic
content_template = """
Write a brief blog post outline for the following topic:
{topic}

Include:
- Introduction
- 3 main points
- Conclusion
"""
content_prompt = PromptTemplate(
    input_variables=["topic"],
    template=content_template
)
content_chain = LLMChain(llm=llm, prompt=content_prompt)

# Combine chains
overall_chain = SimpleSequentialChain(
    chains=[topic_chain, content_chain],
    verbose=True
)

# Run the chain
result = overall_chain.run("artificial intelligence")
print(result)</pre>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Intermediate Section -->
        <div class="content-section" id="intermediate">
            <div class="section-header">
                <h2 class="section-title">
                    <i class="fas fa-cogs text-accent"></i>
                    Intermediate Level
                </h2>
                <p class="section-subtitle">Build sophisticated applications with advanced LangChain features</p>
                <div class="progress-section">
                    <div class="progress-header">
                        <span class="progress-title">Overall Progress</span>
                        <span class="progress-percentage">0%</span>
                    </div>
                    <div class="progress-bar">
                        <div class="progress-fill" style="width: 0%"></div>
                    </div>
                </div>
            </div>

            <div class="modules-grid">
                <!-- Module 1: Memory and Context -->
                <div class="module-card">
                    <div class="module-header">
                        <div class="module-icon">
                            <i class="fas fa-memory"></i>
                        </div>
                        <h3 class="module-title">Memory and Context</h3>
                    </div>
                    <p class="module-description">Learn how to manage conversation memory and maintain context across interactions.</p>
                    
                    <ul class="topics-list">
                        <li>
                            <span class="topic-name">Conversation Buffer Memory</span>
                            <a href="/learn/intermediate/buffer-memory" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Summary Memory</span>
                            <a href="/learn/intermediate/summary-memory" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Vector Store Memory</span>
                            <a href="/learn/intermediate/vector-memory" class="learn-more-btn">Learn More</a>
                        </li>
                    </ul>

                    <div class="code-example">
                        <div class="code-header">
                            <span class="code-title">Conversation Memory Implementation</span>
                            <button class="copy-btn" onclick="copyCode(this)">
                                <i class="fas fa-copy"></i> Copy
                            </button>
                        </div>
                        <div class="code-content">
                            <pre>from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
from langchain.llms import OpenAI

# Initialize memory and LLM
memory = ConversationBufferMemory()
llm = OpenAI(temperature=0.7)

# Create conversation chain with memory
conversation = ConversationChain(
    llm=llm,
    memory=memory,
    verbose=True
)

# Have a conversation
print(conversation.predict(input="Hi, my name is Alice"))
print(conversation.predict(input="What's my name?"))
print(conversation.predict(input="Tell me a joke"))

# Check memory buffer
print("\nMemory Buffer:")
print(memory.buffer)</pre>
                        </div>
                    </div>
                </div>

                <!-- Module 2: Vector Stores and Retrieval -->
                <div class="module-card">
                    <div class="module-header">
                        <div class="module-icon">
                            <i class="fas fa-database"></i>
                        </div>
                        <h3 class="module-title">Vector Stores and Retrieval</h3>
                    </div>
                    <p class="module-description">Master document retrieval using vector embeddings and similarity search.</p>
                    
                    <ul class="topics-list">
                        <li>
                            <span class="topic-name">Embeddings & Vector Stores</span>
                            <a href="/learn/intermediate/embeddings-vectors" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Document Loaders</span>
                            <a href="/learn/intermediate/document-loaders" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Retrieval Chains</span>
                            <a href="/learn/intermediate/retrieval-chains" class="learn-more-btn">Learn More</a>
                        </li>
                    </ul>

                    <div class="code-example">
                        <div class="code-header">
                            <span class="code-title">Vector Store RAG Implementation</span>
                            <button class="copy-btn" onclick="copyCode(this)">
                                <i class="fas fa-copy"></i> Copy
                            </button>
                        </div>
                        <div class="code-content">
                            <pre>from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.document_loaders import TextLoader

# Load and split documents
loader = TextLoader("documents.txt")
documents = loader.load()

text_splitter = CharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=0
)
texts = text_splitter.split_documents(documents)

# Create embeddings and vector store
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(
    texts, 
    embeddings,
    persist_directory="./chroma_db"
)

# Create retrieval QA chain
qa_chain = RetrievalQA.from_chain_type(
    llm=OpenAI(),
    chain_type="stuff",
    retriever=vectorstore.as_retriever(
        search_kwargs={"k": 3}
    )
)

# Ask questions about your documents
query = "What are the main topics discussed?"
result = qa_chain.run(query)
print(result)</pre>
                        </div>
                    </div>
                </div>

                <!-- Module 3: Agents and Tools -->
                <div class="module-card">
                    <div class="module-header">
                        <div class="module-icon">
                            <i class="fas fa-robot"></i>
                        </div>
                        <h3 class="module-title">Agents and Tools</h3>
                    </div>
                    <p class="module-description">Create intelligent agents that can use tools and make decisions dynamically.</p>
                    
                    <ul class="topics-list">
                        <li>
                            <span class="topic-name">Agent Types & Concepts</span>
                            <a href="/learn/intermediate/agent-types" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Custom Tools</span>
                            <a href="/learn/intermediate/custom-tools" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Tool Integration</span>
                            <a href="/learn/intermediate/tool-integration" class="learn-more-btn">Learn More</a>
                        </li>
                    </ul>

                    <div class="code-example">
                        <div class="code-header">
                            <span class="code-title">Custom Agent with Tools</span>
                            <button class="copy-btn" onclick="copyCode(this)">
                                <i class="fas fa-copy"></i> Copy
                            </button>
                        </div>
                        <div class="code-content">
                            <pre>from langchain.agents import initialize_agent, Tool
from langchain.agents import AgentType
from langchain.llms import OpenAI
import requests

def get_weather(city: str) -> str:
    """Get current weather for a city"""
    # Mock weather API call
    return f"The weather in {city} is sunny, 22°C"

def calculator(expression: str) -> str:
    """Evaluate mathematical expressions"""
    try:
        result = eval(expression)
        return f"The result is: {result}"
    except:
        return "Invalid mathematical expression"

# Define tools
tools = [
    Tool(
        name="Weather",
        func=get_weather,
        description="Get weather information for a city"
    ),
    Tool(
        name="Calculator",
        func=calculator,
        description="Perform mathematical calculations"
    )
]

# Initialize agent
llm = OpenAI(temperature=0)
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

# Use the agent
response = agent.run(
    "What's the weather in Paris and what's 25 * 4?"
)
print(response)</pre>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Advanced Section -->
        <div class="content-section" id="advanced">
            <div class="section-header">
                <h2 class="section-title">
                    <i class="fas fa-rocket text-accent"></i>
                    Advanced Level
                </h2>
                <p class="section-subtitle">Master production-ready deployments and advanced optimization techniques</p>
                <div class="progress-section">
                    <div class="progress-header">
                        <span class="progress-title">Overall Progress</span>
                        <span class="progress-percentage">0%</span>
                    </div>
                    <div class="progress-bar">
                        <div class="progress-fill" style="width: 0%"></div>
                    </div>
                </div>
            </div>

            <div class="modules-grid">
                <!-- Module 1: Custom Components -->
                <div class="module-card">
                    <div class="module-header">
                        <div class="module-icon">
                            <i class="fas fa-puzzle-piece"></i>
                        </div>
                        <h3 class="module-title">Custom Components</h3>
                    </div>
                    <p class="module-description">Build custom LangChain components tailored to your specific requirements.</p>
                    
                    <ul class="topics-list">
                        <li>
                            <span class="topic-name">Custom LLM Wrappers</span>
                            <a href="/learn/advanced/custom-llm-wrappers" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Custom Chains</span>
                            <a href="/learn/advanced/custom-chains" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Custom Memory Systems</span>
                            <a href="/learn/advanced/custom-memory" class="learn-more-btn">Learn More</a>
                        </li>
                    </ul>

                    <div class="code-example">
                        <div class="code-header">
                            <span class="code-title">Custom LLM Implementation</span>
                            <button class="copy-btn" onclick="copyCode(this)">
                                <i class="fas fa-copy"></i> Copy
                            </button>
                        </div>
                        <div class="code-content">
                            <pre>from langchain.llms.base import LLM
from typing import Optional, List, Any
import requests

class CustomAPILLM(LLM):
    """Custom LLM that calls your own API"""
    
    api_url: str
    temperature: float = 0.7
    max_tokens: int = 256
    
    @property
    def _llm_type(self) -> str:
        return "custom_api"
    
    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[Any] = None,
    ) -> str:
        """Call the custom API"""
        payload = {
            "prompt": prompt,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "stop": stop or []
        }
        
        response = requests.post(
            self.api_url,
            json=payload,
            headers={"Content-Type": "application/json"}
        )
        
        if response.status_code == 200:
            return response.json()["text"]
        else:
            raise Exception(f"API call failed: {response.status_code}")
    
    @property
    def _identifying_params(self) -> dict:
        """Return identifying parameters"""
        return {
            "api_url": self.api_url,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens
        }

# Usage
custom_llm = CustomAPILLM(
    api_url="https://your-api-endpoint.com/generate"
)

response = custom_llm("Explain quantum computing")
print(response)</pre>
                        </div>
                    </div>
                </div>

                <!-- Module 2: Production Deployment -->
                <div class="module-card">
                    <div class="module-header">
                        <div class="module-icon">
                            <i class="fas fa-cloud"></i>
                        </div>
                        <h3 class="module-title">Production Deployment</h3>
                    </div>
                    <p class="module-description">Deploy LangChain applications to production with proper scaling and monitoring.</p>
                    
                    <ul class="topics-list">
                        <li>
                            <span class="topic-name">FastAPI Integration</span>
                            <a href="/learn/advanced/fastapi-integration" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Docker & Containerization</span>
                            <a href="/learn/advanced/docker-deployment" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Monitoring & Logging</span>
                            <a href="/learn/advanced/monitoring-logging" class="learn-more-btn">Learn More</a>
                        </li>
                    </ul>

                    <div class="code-example">
                        <div class="code-header">
                            <span class="code-title">FastAPI Production Setup</span>
                            <button class="copy-btn" onclick="copyCode(this)">
                                <i class="fas fa-copy"></i> Copy
                            </button>
                        </div>
                        <div class="code-content">
                            <pre>from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from langchain.chains import LLMChain
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
import logging
import time

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="LangChain API", version="1.0.0")

# Request/Response models
class QueryRequest(BaseModel):
    prompt: str
    temperature: float = 0.7
    max_tokens: int = 256

class QueryResponse(BaseModel):
    response: str
    processing_time: float

# Initialize LangChain components
llm = OpenAI(temperature=0.7)
prompt_template = PromptTemplate(
    input_variables=["query"],
    template="Answer the following question: {query}"
)
chain = LLMChain(llm=llm, prompt=prompt_template)

@app.post("/query", response_model=QueryResponse)
async def query_llm(request: QueryRequest):
    """Process LLM query with monitoring"""
    start_time = time.time()
    
    try:
        logger.info(f"Processing query: {request.prompt[:50]}...")
        
        # Update LLM parameters
        chain.llm.temperature = request.temperature
        chain.llm.max_tokens = request.max_tokens
        
        # Process the query
        response = chain.run(query=request.prompt)
        
        processing_time = time.time() - start_time
        logger.info(f"Query processed in {processing_time:.2f}s")
        
        return QueryResponse(
            response=response,
            processing_time=processing_time
        )
        
    except Exception as e:
        logger.error(f"Error processing query: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "timestamp": time.time()}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)</pre>
                        </div>
                    </div>
                </div>

                <!-- Module 3: Performance Optimization -->
                <div class="module-card">
                    <div class="module-header">
                        <div class="module-icon">
                            <i class="fas fa-tachometer-alt"></i>
                        </div>
                        <h3 class="module-title">Performance Optimization</h3>
                    </div>
                    <p class="module-description">Optimize your LangChain applications for speed, cost, and reliability.</p>
                    
                    <ul class="topics-list">
                        <li>
                            <span class="topic-name">Caching Strategies</span>
                            <a href="/learn/advanced/caching-strategies" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Streaming & Async</span>
                            <a href="/learn/advanced/streaming-async" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Cost Optimization</span>
                            <a href="/learn/advanced/cost-optimization" class="learn-more-btn">Learn More</a>
                        </li>
                    </ul>

                    <div class="code-example">
                        <div class="code-header">
                            <span class="code-title">Streaming & Caching Implementation</span>
                            <button class="copy-btn" onclick="copyCode(this)">
                                <i class="fas fa-copy"></i> Copy
                            </button>
                        </div>
                        <div class="code-content">
                            <pre>import asyncio
from langchain.cache import InMemoryCache
from langchain.llms import OpenAI
from langchain.callbacks.base import BaseCallbackHandler
from langchain.schema import LLMResult
import langchain

# Enable caching globally
langchain.llm_cache = InMemoryCache()

class StreamingCallbackHandler(BaseCallbackHandler):
    """Custom callback for streaming responses"""
    
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        """Handle new tokens as they arrive"""
        print(token, end="", flush=True)

async def process_queries_async(queries: list) -> list:
    """Process multiple queries asynchronously"""
    llm = OpenAI(
        streaming=True,
        callbacks=[StreamingCallbackHandler()],
        temperature=0.7
    )
    
    # Create async tasks
    tasks = []
    for query in queries:
        task = asyncio.create_task(
            llm.agenerate([query])
        )
        tasks.append(task)
    
    # Wait for all tasks to complete
    results = await asyncio.gather(*tasks)
    return results

# Example usage
queries = [
    "Explain machine learning",
    "What is blockchain?",
    "How does quantum computing work?"
]

# Run async processing
async def main():
    print("Processing queries with caching and streaming...")
    results = await process_queries_async(queries)
    
    print("\n\nSecond run (should use cache):")
    results_cached = await process_queries_async(queries[:2])

# Run the async function
asyncio.run(main())</pre>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Specialized Section -->
        <div class="content-section" id="specialized">
            <div class="section-header">
                <h2 class="section-title">
                    <i class="fas fa-brain text-accent"></i>
                    Specialized Applications
                </h2>
                <p class="section-subtitle">Explore domain-specific applications and cutting-edge implementations</p>
                <div class="progress-section">
                    <div class="progress-header">
                        <span class="progress-title">Overall Progress</span>
                        <span class="progress-percentage">0%</span>
                    </div>
                    <div class="progress-bar">
                        <div class="progress-fill" style="width: 0%"></div>
                    </div>
                </div>
            </div>

            <div class="modules-grid">
                <!-- Module 1: Multimodal Applications -->
                <div class="module-card">
                    <div class="module-header">
                        <div class="module-icon">
                            <i class="fas fa-images"></i>
                        </div>
                        <h3 class="module-title">Multimodal Applications</h3>
                    </div>
                    <p class="module-description">Work with text, images, audio, and video in unified applications.</p>
                    
                    <ul class="topics-list">
                        <li>
                            <span class="topic-name">Vision-Language Models</span>
                            <a href="/learn/specialized/vision-language" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Audio Processing</span>
                            <a href="/learn/specialized/audio-processing" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Document Analysis</span>
                            <a href="/learn/specialized/document-analysis" class="learn-more-btn">Learn More</a>
                        </li>
                    </ul>

                    <div class="code-example">
                        <div class="code-header">
                            <span class="code-title">Image Analysis Chain</span>
                            <button class="copy-btn" onclick="copyCode(this)">
                                <i class="fas fa-copy"></i> Copy
                            </button>
                        </div>
                        <div class="code-content">
                            <pre>from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.llms.base import LLM
import base64
import requests
from PIL import Image

class VisionLLM(LLM):
    """Custom LLM for image analysis"""
    
    @property
    def _llm_type(self) -> str:
        return "vision_llm"
    
    def _call(self, prompt: str, stop=None, **kwargs) -> str:
        # Extract image from prompt
        if "IMAGE:" in prompt:
            parts = prompt.split("IMAGE:")
            text_prompt = parts[0]
            image_path = parts[1].strip()
            
            # Process image
            with open(image_path, "rb") as img_file:
                encoded_image = base64.b64encode(img_file.read()).decode()
            
            # Call vision API (example)
            response = self._analyze_image(encoded_image, text_prompt)
            return response
        
        return "No image provided"
    
    def _analyze_image(self, encoded_image: str, prompt: str) -> str:
        """Analyze image using vision model"""
        # Mock implementation - replace with actual vision API
        return f"Analysis of image: The image contains various elements related to the query: {prompt}"

# Create multimodal chain
vision_llm = VisionLLM()

image_analysis_template = """
Analyze the provided image and answer the following question:
{question}

Consider the visual elements, context, and any text visible in the image.

IMAGE: {image_path}
"""

image_prompt = PromptTemplate(
    input_variables=["question", "image_path"],
    template=image_analysis_template
)

image_chain = LLMChain(
    llm=vision_llm,
    prompt=image_prompt
)

# Use the chain
result = image_chain.run(
    question="What objects do you see in this image?",
    image_path="./sample_image.jpg"
)
print(result)</pre>
                        </div>
                    </div>
                </div>

                <!-- Module 2: Code Generation -->
                <div class="module-card">
                    <div class="module-header">
                        <div class="module-icon">
                            <i class="fas fa-code"></i>
                        </div>
                        <h3 class="module-title">Code Generation & Analysis</h3>
                    </div>
                    <p class="module-description">Build applications that generate, analyze, and optimize code across multiple languages.</p>
                    
                    <ul class="topics-list">
                        <li>
                            <span class="topic-name">Code Generation Chains</span>
                            <a href="/learn/specialized/code-generation" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Code Review Automation</span>
                            <a href="/learn/specialized/code-review" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Documentation Generation</span>
                            <a href="/learn/specialized/docs-generation" class="learn-more-btn">Learn More</a>
                        </li>
                    </ul>

                    <div class="code-example">
                        <div class="code-header">
                            <span class="code-title">Intelligent Code Assistant</span>
                            <button class="copy-btn" onclick="copyCode(this)">
                                <i class="fas fa-copy"></i> Copy
                            </button>
                        </div>
                        <div class="code-content">
                            <pre>from langchain.chains import SequentialChain, LLMChain
from langchain.prompts import PromptTemplate
from langchain.llms import OpenAI
from langchain.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field
from typing import List

class CodeAnalysis(BaseModel):
    """Structured code analysis output"""
    language: str = Field(description="Programming language detected")
    complexity: str = Field(description="Code complexity level")
    issues: List[str] = Field(description="List of potential issues")
    suggestions: List[str] = Field(description="Improvement suggestions")
    documentation: str = Field(description="Generated documentation")

class CodeAssistantChain:
    def __init__(self):
        self.llm = OpenAI(temperature=0.3)
        self.parser = PydanticOutputParser(pydantic_object=CodeAnalysis)
        self._setup_chains()
    
    def _setup_chains(self):
        # Code analysis chain
        analysis_template = """
        Analyze the following code and identify:
        1. Programming language
        2. Complexity level (Simple/Medium/Complex)
        3. Potential issues or bugs
        4. Improvement suggestions
        
        Code:
        {code}
        
        {format_instructions}
        """
        
        analysis_prompt = PromptTemplate(
            template=analysis_template,
            input_variables=["code"],
            partial_variables={
                "format_instructions": self.parser.get_format_instructions()
            }
        )
        
        self.analysis_chain = LLMChain(
            llm=self.llm,
            prompt=analysis_prompt,
            output_key="analysis"
        )
        
        # Code improvement chain
        improvement_template = """
        Based on the analysis: {analysis}
        
        Provide an improved version of the original code:
        {code}
        
        Focus on:
        - Fixing identified issues
        - Improving readability
        - Following best practices
        - Adding error handling where needed
        """
        
        improvement_prompt = PromptTemplate(
            template=improvement_template,
            input_variables=["analysis", "code"]
        )
        
        self.improvement_chain = LLMChain(
            llm=self.llm,
            prompt=improvement_prompt,
            output_key="improved_code"
        )
        
        # Create sequential chain
        self.full_chain = SequentialChain(
            chains=[self.analysis_chain, self.improvement_chain],
            input_variables=["code"],
            output_variables=["analysis", "improved_code"],
            verbose=True
        )
    
    def analyze_and_improve(self, code: str) -> dict:
        """Analyze code and provide improvements"""
        result = self.full_chain({"code": code})
        
        # Parse analysis
        try:
            analysis = self.parser.parse(result["analysis"])
            result["parsed_analysis"] = analysis
        except:
            result["parsed_analysis"] = None
            
        return result

# Usage example
assistant = CodeAssistantChain()

sample_code = '''
def calculate_average(numbers):
    total = 0
    for i in range(len(numbers)):
        total = total + numbers[i]
    return total / len(numbers)
'''

result = assistant.analyze_and_improve(sample_code)
print("Analysis:", result["parsed_analysis"])
print("\nImproved Code:", result["improved_code"])</pre>
                        </div>
                    </div>
                </div>

                <!-- Module 3: Research & Analysis -->
                <div class="module-card">
                    <div class="module-header">
                        <div class="module-icon">
                            <i class="fas fa-search"></i>
                        </div>
                        <h3 class="module-title">Research & Analysis</h3>
                    </div>
                    <p class="module-description">Build applications for automated research, data analysis, and report generation.</p>
                    
                    <ul class="topics-list">
                        <li>
                            <span class="topic-name">Web Research Agents</span>
                            <a href="/learn/specialized/web-research" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Data Analysis Chains</span>
                            <a href="/learn/specialized/data-analysis" class="learn-more-btn">Learn More</a>
                        </li>
                        <li>
                            <span class="topic-name">Report Generation</span>
                            <a href="/learn/specialized/report-generation" class="learn-more-btn">Learn More</a>
                        </li>
                    </ul>

                    <div class="code-example">
                        <div class="code-header">
                            <span class="code-title">Automated Research Pipeline</span>
                            <button class="copy-btn" onclick="copyCode(this)">
                                <i class="fas fa-copy"></i> Copy
                            </button>
                        </div>
                        <div class="code-content">
                            <pre>from langchain.agents import initialize_agent, Tool
from langchain.agents import AgentType
from langchain.llms import OpenAI
from langchain.utilities import SerpAPIWrapper
from langchain.chains.summarize import load_summarize_chain
from langchain.text_splitter import TokenTextSplitter
import requests
from typing import List

class ResearchAgent:
    def __init__(self, serp_api_key: str):
        self.llm = OpenAI(temperature=0.1)
        self.search = SerpAPIWrapper(serpapi_api_key=serp_api_key)
        self.summarizer = load_summarize_chain(
            self.llm, 
            chain_type="map_reduce"
        )
        self._setup_tools()
        self._setup_agent()
    
    def _setup_tools(self):
        """Setup research tools"""
        def web_search(query: str) -> str:
            """Search the web for information"""
            return self.search.run(query)
        
        def summarize_text(text: str) -> str:
            """Summarize long text"""
            splitter = TokenTextSplitter(chunk_size=4000)
            docs = splitter.create_documents([text])
            summary = self.summarizer.run(docs)
            return summary
        
        def analyze_trends(topic: str) -> str:
            """Analyze trends for a given topic"""
            search_results = self.search.run(f"{topic} trends 2024")
            return f"Trend analysis for {topic}: {search_results[:500]}..."
        
        self.tools = [
            Tool(
                name="WebSearch",
                func=web_search,
                description="Search the web for current information"
            ),
            Tool(
                name="TextSummarizer",
                func=summarize_text,
                description="Summarize long pieces of text"
            ),
            Tool(
                name="TrendAnalyzer",
                func=analyze_trends,
                description="Analyze current trends for a topic"
            )
        ]
    
    def _setup_agent(self):
        """Initialize the research agent"""
        self.agent = initialize_agent(
            self.tools,
            self.llm,
            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
            verbose=True,
            max_iterations=10
        )
    
    def conduct_research(self, research_topic: str) -> str:
        """Conduct comprehensive research on a topic"""
        research_prompt = f"""
        Conduct comprehensive research on: {research_topic}
        
        Please:
        1. Search for current information and developments
        2. Analyze recent trends and patterns  
        3. Summarize key findings
        4. Provide insights and implications
        
        Structure your response as a research report with:
        - Executive Summary
        - Key Findings
        - Trends Analysis
        - Conclusions
        """
        
        return self.agent.run(research_prompt)

# Usage (requires SERP API key)
# researcher = ResearchAgent(serp_api_key="your_serp_api_key")
# report = researcher.conduct_research("Artificial Intelligence in Healthcare 2024")
# print(report)

# Mock example without API key
print("""
Research Agent Example:
This agent would search the web, analyze trends, and generate
comprehensive reports on any given topic using multiple tools
and structured research methodologies.
""")</pre>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- JavaScript -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <script>
        // Navigation functionality
        document.addEventListener('DOMContentLoaded', function() {
            const navCards = document.querySelectorAll('.nav-card');
            const contentSections = document.querySelectorAll('.content-section');
            
            navCards.forEach(card => {
                card.addEventListener('click', function() {
                    const targetSection = this.getAttribute('data-section');
                    
                    // Update active nav card
                    navCards.forEach(c => c.classList.remove('active'));
                    this.classList.add('active');
                    
                    // Show target section
                    contentSections.forEach(section => {
                        section.classList.remove('active');
                    });
                    document.getElementById(targetSection).classList.add('active');
                    
                    // Scroll to top of content
                    window.scrollTo({ top: 0, behavior: 'smooth' });
                });
            });
        });

        // Copy code functionality
        function copyCode(button) {
            const codeBlock = button.parentElement.nextElementSibling.querySelector('pre');
            const code = codeBlock.textContent;
            
            navigator.clipboard.writeText(code).then(function() {
                const originalText = button.innerHTML;
                button.innerHTML = '<i class="fas fa-check"></i> Copied!';
                button.style.backgroundColor = 'var(--success-color)';
                
                setTimeout(function() {
                    button.innerHTML = originalText;
                    button.style.backgroundColor = 'var(--accent-color)';
                }, 2000);
            });
        }

        // Progress simulation (for demo purposes)
        function updateProgress(sectionId, percentage) {
            const section = document.getElementById(sectionId);
            const progressFill = section.querySelector('.progress-fill');
            const progressText = section.querySelector('.progress-percentage');
            
            progressFill.style.width = percentage + '%';
            progressText.textContent = percentage + '%';
        }

        // Simulate progress updates
        setTimeout(() => {
            updateProgress('beginner', 25);
            updateProgress('intermediate', 15);
            updateProgress('advanced', 5);
            updateProgress('specialized', 0);
        }, 1000);
    </script>
</body>
</html>
