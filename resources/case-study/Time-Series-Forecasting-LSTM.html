<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Time-Series Forecasting with LSTM: Energy Consumption Predictions</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        :root {
            --primary: #2c3e8f;
            --secondary: #4a6cf7;
            --accent: #ff6b6b;
            --light: #f8f9fa;
            --dark: #343a40;
            --gray: #6c757d;
            --success: #28a745;
            --warning: #ffc107;
            --danger: #dc3545;
            --info: #17a2b8;
        }
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        
        body {
            background-color: #f5f7fa;
            color: #333;
            line-height: 1.6;
        }
        
        .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px;
        }
        
        header {
            background: linear-gradient(135deg, var(--primary), var(--secondary));
            color: white;
            padding: 2rem 0;
            text-align: center;
            border-radius: 10px;
            margin-bottom: 2rem;
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        }
        
        header h1 {
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
        }
        
        header p {
            font-size: 1.2rem;
            max-width: 800px;
            margin: 0 auto;
        }
        
        .nav-tabs {
            display: flex;
            flex-wrap: wrap;
            background: white;
            border-radius: 10px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.08);
            margin-bottom: 2rem;
            overflow: hidden;
        }
        
        .nav-tab {
            flex: 1;
            min-width: 150px;
            padding: 15px 20px;
            text-align: center;
            cursor: pointer;
            transition: all 0.3s ease;
            border-bottom: 3px solid transparent;
        }
        
        .nav-tab:hover {
            background-color: #f0f4ff;
        }
        
        .nav-tab.active {
            background-color: #f0f4ff;
            border-bottom: 3px solid var(--secondary);
            color: var(--primary);
            font-weight: 600;
        }
        
        .tab-content {
            display: none;
            animation: fadeIn 0.5s ease;
        }
        
        .tab-content.active {
            display: block;
        }
        
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        
        .card {
            background: white;
            border-radius: 10px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.08);
            padding: 25px;
            margin-bottom: 25px;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }
        
        .card:hover {
            transform: translateY(-5px);
            box-shadow: 0 8px 24px rgba(0,0,0,0.12);
        }
        
        .card-header {
            display: flex;
            align-items: center;
            margin-bottom: 20px;
            padding-bottom: 15px;
            border-bottom: 1px solid #eee;
        }
        
        .card-header i {
            font-size: 1.8rem;
            color: var(--secondary);
            margin-right: 15px;
        }
        
        .card-header h2 {
            color: var(--primary);
            font-size: 1.8rem;
        }
        
        .card-header .badge {
            margin-left: auto;
            background: var(--secondary);
            color: white;
            padding: 5px 12px;
            border-radius: 20px;
            font-size: 0.9rem;
        }
        
        .card-body h3 {
            color: var(--primary);
            margin: 20px 0 10px;
            font-size: 1.4rem;
        }
        
        .card-body p {
            margin-bottom: 15px;
        }
        
        .card-body ul, .card-body ol {
            margin-left: 20px;
            margin-bottom: 15px;
        }
        
        .card-body li {
            margin-bottom: 8px;
        }
        
        .data-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            font-size: 0.9rem;
        }
        
        .data-table th, .data-table td {
            padding: 12px 15px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        
        .data-table th {
            background-color: #f8f9fa;
            font-weight: 600;
            color: var(--primary);
        }
        
        .data-table tr:hover {
            background-color: #f8f9fa;
        }
        
        .code-block {
            background: #f8f9fa;
            border-left: 4px solid var(--secondary);
            padding: 15px;
            margin: 20px 0;
            border-radius: 0 5px 5px 0;
            font-family: 'Courier New', Courier, monospace;
            overflow-x: auto;
        }
        
        .code-block pre {
            margin: 0;
            white-space: pre-wrap;
        }
        
        .highlight {
            background-color: #fff9c4;
            padding: 2px 4px;
            border-radius: 3px;
        }
        
        .step-box {
            background: #f0f4ff;
            border-left: 4px solid var(--secondary);
            padding: 15px;
            margin: 15px 0;
            border-radius: 0 5px 5px 0;
        }
        
        .step-box h4 {
            color: var(--primary);
            margin-bottom: 10px;
        }
        
        .transform-box {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
            margin: 20px 0;
        }
        
        .transform-step {
            flex: 1;
            min-width: 300px;
            background: white;
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            padding: 15px;
            position: relative;
        }
        
        .transform-step h4 {
            color: var(--primary);
            margin-bottom: 10px;
            padding-bottom: 8px;
            border-bottom: 1px dashed #ddd;
        }
        
        .transform-step .arrow {
            position: absolute;
            right: -30px;
            top: 50%;
            transform: translateY(-50%);
            color: var(--secondary);
            font-size: 1.5rem;
            z-index: 1;
        }
        
        .formula {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            margin: 15px 0;
            text-align: center;
            font-style: italic;
        }
        
        .pipeline-diagram {
            display: flex;
            flex-direction: column;
            align-items: center;
            margin: 30px 0;
        }
        
        .pipeline-step {
            background: white;
            border: 2px solid var(--secondary);
            border-radius: 10px;
            padding: 15px 25px;
            margin: 10px 0;
            width: 80%;
            max-width: 600px;
            text-align: center;
            position: relative;
            box-shadow: 0 2px 8px rgba(0,0,0,0.08);
        }
        
        .pipeline-step::after {
            content: '';
            position: absolute;
            bottom: -20px;
            left: 50%;
            transform: translateX(-50%);
            width: 0;
            height: 0;
            border-left: 15px solid transparent;
            border-right: 15px solid transparent;
            border-top: 15px solid var(--secondary);
        }
        
        .pipeline-step:last-child::after {
            display: none;
        }
        
        .model-comparison {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
            margin: 20px 0;
        }
        
        .model-card {
            flex: 1;
            min-width: 300px;
            background: white;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 8px rgba(0,0,0,0.08);
        }
        
        .model-header {
            background: var(--primary);
            color: white;
            padding: 12px 15px;
            font-weight: 600;
            font-size: 1.1rem;
        }
        
        .model-body {
            padding: 15px;
        }
        
        .model-body ul {
            margin: 0;
            padding-left: 20px;
        }
        
        .model-body li {
            margin-bottom: 8px;
        }
        
        .footer {
            text-align: center;
            padding: 20px;
            margin-top: 30px;
            color: var(--gray);
            font-size: 0.9rem;
        }
        
        @media (max-width: 768px) {
            .nav-tab {
                min-width: 120px;
                padding: 12px 15px;
                font-size: 0.9rem;
            }
            
            .transform-step .arrow {
                display: none;
            }
            
            .pipeline-step {
                width: 95%;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Time-Series Forecasting with LSTM</h1>
            <p>A comprehensive guide to energy consumption predictions using LSTM networks and time series analysis</p>
        </header>
        
        <div class="nav-tabs">
            <div class="nav-tab active" data-tab="overview">Overview</div>
            <div class="nav-tab" data-tab="data">Data Sources</div>
            <div class="nav-tab" data-tab="pipeline">Solution Pipeline</div>
            <div class="nav-tab" data-tab="transformations">Transformations</div>
            <div class="nav-tab" data-tab="models">Models</div>
            <div class="nav-tab" data-tab="evaluation">Evaluation</div>
            <div class="nav-tab" data-tab="implementation">Implementation</div>
        </div>
        
        <div class="tab-content active" id="overview">
            <div class="card">
                <div class="card-header">
                    <i class="fas fa-bullseye"></i>
                    <h2>Problem Statement</h2>
                    <span class="badge">Business Case</span>
                </div>
                <div class="card-body">
                    <p><strong>Business:</strong> Energy utility company serving residential and commercial customers.</p>
                    <p><strong>Goals:</strong></p>
                    <ol>
                        <li>Forecast <span class="highlight">energy consumption</span> at different granularities (hourly, daily, weekly).</li>
                        <li>Predict <span class="highlight">peak demand periods</span> to optimize energy generation and distribution.</li>
                        <li>Identify <span class="highlight">consumption patterns</span> to provide personalized recommendations to customers.</li>
                        <li>Reduce <span class="highlight">energy waste</span> and improve grid stability.</li>
                    </ol>
                    <p><strong>Why hard:</strong> Energy consumption is influenced by multiple factors including weather conditions, time of day, day of week, seasonal patterns, holidays, and special events. The data exhibits complex nonlinear patterns, multiple seasonalities, and potential outliers.</p>
                </div>
            </div>
            
            <div class="card">
                <div class="card-header">
                    <i class="fas fa-lightbulb"></i>
                    <h2>Solution Overview</h2>
                    <span class="badge">High-Level</span>
                </div>
                <div class="card-body">
                    <p>Our solution leverages Long Short-Term Memory (LSTM) networks, a type of recurrent neural network well-suited for time series forecasting, to predict energy consumption patterns:</p>
                    <div class="model-comparison">
                        <div class="model-card">
                            <div class="model-header">LSTM Networks</div>
                            <div class="model-body">
                                <ul>
                                    <li>Captures long-term dependencies</li>
                                    <li>Models complex temporal patterns</li>
                                    <li>Handles multiple seasonalities</li>
                                    <li>Adapts to changing patterns</li>
                                </ul>
                            </div>
                        </div>
                        <div class="model-card">
                            <div class="model-header">Feature Engineering</div>
                            <div class="model-body">
                                <ul>
                                    <li>Time-based features (hour, day, month)</li>
                                    <li>Weather data integration</li>
                                    <li>Lag features for autocorrelation</li>
                                    <li>Holiday and event indicators</li>
                                </ul>
                            </div>
                        </div>
                        <div class="model-card">
                            <div class="model-header">Ensemble Methods</div>
                            <div class="model-body">
                                <ul>
                                    <li>Combines LSTM with traditional models</li>
                                    <li>Improves forecast robustness</li>
                                    <li>Reduces overfitting risk</li>
                                    <li>Handles uncertainty quantification</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="tab-content" id="data">
            <div class="card">
                <div class="card-header">
                    <i class="fas fa-database"></i>
                    <h2>Data Sources & Canonical Schemas</h2>
                    <span class="badge">Raw Inputs</span>
                </div>
                <div class="card-body">
                    <h3>a. Energy consumption data (time-series)</h3>
                    <table class="data-table">
                        <thead>
                            <tr>
                                <th>timestamp</th>
                                <th>consumption_kwh</th>
                                <th>customer_id</th>
                                <th>customer_type</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>2025-08-20 08:00:00</td>
                                <td>1.25</td>
                                <td>CUST789</td>
                                <td>residential</td>
                            </tr>
                            <tr>
                                <td>2025-08-20 08:00:00</td>
                                <td>45.80</td>
                                <td>CUST456</td>
                                <td>commercial</td>
                            </tr>
                            <tr>
                                <td>2025-08-20 09:00:00</td>
                                <td>1.15</td>
                                <td>CUST789</td>
                                <td>residential</td>
                            </tr>
                        </tbody>
                    </table>
                    
                    <h3>b. Weather data (time-indexed)</h3>
                    <table class="data-table">
                        <thead>
                            <tr>
                                <th>timestamp</th>
                                <th>temp_c</th>
                                <th>humidity_pct</th>
                                <th>wind_speed_kmh</th>
                                <th>weather_condition</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>2025-08-20 08:00:00</td>
                                <td>22.5</td>
                                <td>65</td>
                                <td>12.3</td>
                                <td>partly_cloudy</td>
                            </tr>
                            <tr>
                                <td>2025-08-20 09:00:00</td>
                                <td>23.1</td>
                                <td>63</td>
                                <td>11.8</td>
                                <td>partly_cloudy</td>
                            </tr>
                        </tbody>
                    </table>
                    
                    <h3>c. Calendar data</h3>
                    <table class="data-table">
                        <thead>
                            <tr>
                                <th>date</th>
                                <th>day_of_week</th>
                                <th>is_holiday</th>
                                <th>holiday_name</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>2025-08-20</td>
                                <td>3</td>
                                <td>0</td>
                                <td>NULL</td>
                            </tr>
                            <tr>
                                <td>2025-09-01</td>
                                <td>1</td>
                                <td>1</td>
                                <td>Labor Day</td>
                            </tr>
                        </tbody>
                    </table>
                    
                    <h3>d. Customer metadata</h3>
                    <table class="data-table">
                        <thead>
                            <tr>
                                <th>customer_id</th>
                                <th>location</th>
                                <th>home_size_sqft</th>
                                <th>num_occupants</th>
                                <th>has_solar</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>CUST789</td>
                                <td>Zone_A</td>
                                <td>1850</td>
                                <td>4</td>
                                <td>1</td>
                            </tr>
                            <tr>
                                <td>CUST456</td>
                                <td>Zone_B</td>
                                <td>8500</td>
                                <td>25</td>
                                <td>0</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
        </div>
        
        <div class="tab-content" id="pipeline">
            <div class="card">
                <div class="card-header">
                    <i class="fas fa-sitemap"></i>
                    <h2>High-Level Solution Architecture</h2>
                    <span class="badge">Pipeline</span>
                </div>
                <div class="card-body">
                    <div class="pipeline-diagram">
                        <div class="pipeline-step">1. Data collection & integration from multiple sources</div>
                        <div class="pipeline-step">2. Data cleaning & preprocessing (handling missing values, outliers)</div>
                        <div class="pipeline-step">3. Feature engineering (time-based, weather, lag features)</div>
                        <div class="pipeline-step">4. Data normalization & sequence generation for LSTM</div>
                        <div class="pipeline-step">5. Model training (LSTM with multiple configurations)</div>
                        <div class="pipeline-step">6. Model validation & hyperparameter tuning</div>
                        <div class="pipeline-step">7. Ensemble with traditional time series models</div>
                        <div class="pipeline-step">8. Forecast generation & uncertainty quantification</div>
                        <div class="pipeline-step">9. Deployment & monitoring with continuous retraining</div>
                    </div>
                    
                    <h3>Detailed Pipeline Steps</h3>
                    <ol>
                        <li><strong>Data collection & integration:</strong> Energy consumption data is collected from smart meters, weather data from meteorological services, and calendar data from public sources.</li>
                        <li><strong>Data cleaning & preprocessing:</strong> Missing values are imputed, outliers are detected and handled, and data is aligned to a consistent time interval.</li>
                        <li><strong>Feature engineering:</strong> Time-based features (hour, day, month), weather features, lag features, and holiday indicators are created to enrich the dataset.</li>
                        <li><strong>Data normalization & sequence generation:</strong> Features are normalized to a common scale, and sequences of historical data are created for LSTM input.</li>
                        <li><strong>Model training:</strong> LSTM models with different architectures and hyperparameters are trained on the sequence data.</li>
                        <li><strong>Model validation & hyperparameter tuning:</strong> Models are validated using time-series cross-validation, and hyperparameters are optimized.</li>
                        <li><strong>Ensemble with traditional models:</strong> LSTM predictions are combined with predictions from ARIMA or Prophet models to improve robustness.</li>
                        <li><strong>Forecast generation & uncertainty quantification:</strong> Final forecasts are generated with prediction intervals to quantify uncertainty.</li>
                        <li><strong>Deployment & monitoring:</strong> Models are deployed to production, and their performance is continuously monitored with periodic retraining.</li>
                    </ol>
                </div>
            </div>
        </div>
        
        <div class="tab-content" id="transformations">
            <div class="card">
                <div class="card-header">
                    <i class="fas fa-exchange-alt"></i>
                    <h2>Data Transformations</h2>
                    <span class="badge">Deep Dive</span>
                </div>
                <div class="card-body">
                    <h3>4.A Data Cleaning & Preprocessing</h3>
                    <p><strong>Goal:</strong> Handle missing values, outliers, and align data to a consistent time interval.</p>
                    
                    <div class="step-box">
                        <h4>1) Handle missing values</h4>
                        <p><strong>Before:</strong></p>
                        <table class="data-table">
                            <thead>
                                <tr>
                                    <th>timestamp</th>
                                    <th>consumption_kwh</th>
                                    <th>temp_c</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>2025-08-20 08:00:00</td>
                                    <td>1.25</td>
                                    <td>22.5</td>
                                </tr>
                                <tr>
                                    <td>2025-08-20 09:00:00</td>
                                    <td>NULL</td>
                                    <td>23.1</td>
                                </tr>
                                <tr>
                                    <td>2025-08-20 10:00:00</td>
                                    <td>1.35</td>
                                    <td>NULL</td>
                                </tr>
                            </tbody>
                        </table>
                        
                        <p><strong>Transform:</strong></p>
                        <div class="code-block">
                            <pre># Linear interpolation for consumption
df['consumption_kwh'] = df['consumption_kwh'].interpolate(method='linear')

# Forward fill for temperature
df['temp_c'] = df['temp_c'].fillna(method='ffill')</pre>
                        </div>
                        
                        <p><strong>After:</strong></p>
                        <table class="data-table">
                            <thead>
                                <tr>
                                    <th>timestamp</th>
                                    <th>consumption_kwh</th>
                                    <th>temp_c</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>2025-08-20 08:00:00</td>
                                    <td>1.25</td>
                                    <td>22.5</td>
                                </tr>
                                <tr>
                                    <td>2025-08-20 09:00:00</td>
                                    <td>1.30</td>
                                    <td>23.1</td>
                                </tr>
                                <tr>
                                    <td>2025-08-20 10:00:00</td>
                                    <td>1.35</td>
                                    <td>23.1</td>
                                </tr>
                            </tbody>
                        </table>
                        
                        <p><strong>Why:</strong> Energy consumption typically changes gradually, so linear interpolation is appropriate. Weather variables like temperature are stable in the short term, making forward filling suitable.</p>
                    </div>
                    
                    <div class="step-box">
                        <h4>2) Detect and handle outliers</h4>
                        <p><strong>Transform:</strong></p>
                        <div class="code-block">
                            <pre># Using IQR method to detect outliers
Q1 = df['consumption_kwh'].quantile(0.25)
Q3 = df['consumption_kwh'].quantile(0.75)
IQR = Q3 - Q1

# Define outlier bounds
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Cap outliers
df['consumption_kwh'] = df['consumption_kwh'].clip(lower_bound, upper_bound)</pre>
                        </div>
                        
                        <p><strong>Why:</strong> Outliers can significantly impact model performance. Capping extreme values rather than removing them preserves the time series structure while reducing their influence.</p>
                    </div>
                    
                    <h3>4.B Feature Engineering</h3>
                    <p><strong>Goal:</strong> Create features that capture temporal patterns, weather effects, and other factors influencing energy consumption.</p>
                    
                    <div class="step-box">
                        <h4>1) Time-based features</h4>
                        <p><strong>Transform:</strong></p>
                        <div class="code-block">
                            <pre># Extract time components
df['hour'] = df['timestamp'].dt.hour
df['day_of_week'] = df['timestamp'].dt.dayofweek
df['day_of_month'] = df['timestamp'].dt.day
df['month'] = df['timestamp'].dt.month
df['year'] = df['timestamp'].dt.year

# Create cyclical features for hour and month
df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)

# Weekend indicator
df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)</pre>
                        </div>
                        
                        <p><strong>Why:</strong> Energy consumption follows daily and seasonal patterns. Cyclical encoding ensures the model understands that hour 23 is close to hour 0, and December is close to January.</p>
                    </div>
                    
                    <div class="step-box">
                        <h4>2) Lag features</h4>
                        <p><strong>Transform:</strong></p>
                        <div class="code-block">
                            <pre># Create lag features for consumption
for lag in [1, 2, 3, 6, 12, 24, 48]:  # 1 hour to 2 days ago
    df[f'consumption_lag_{lag}'] = df['consumption_kwh'].shift(lag)

# Create rolling window features
df['consumption_roll_mean_24h'] = df['consumption_kwh'].shift(1).rolling(24).mean()
df['consumption_roll_std_24h'] = df['consumption_kwh'].shift(1).rolling(24).std()
df['consumption_roll_max_24h'] = df['consumption_kwh'].shift(1).rolling(24).max()
df['consumption_roll_min_24h'] = df['consumption_kwh'].shift(1).rolling(24).min()</pre>
                        </div>
                        
                        <p><strong>Why:</strong> Energy consumption is autocorrelated - recent consumption values are good predictors of future values. Rolling statistics capture short-term trends and volatility.</p>
                    </div>
                    
                    <div class="step-box">
                        <h4>3) Weather features</h4>
                        <p><strong>Transform:</strong></p>
                        <div class="code-block">
                            <pre># Create temperature bins
df['temp_bin'] = pd.cut(df['temp_c'], 
                        bins=[-np.inf, 10, 18, 25, 30, np.inf],
                        labels=['very_cold', 'cold', 'comfortable', 'warm', 'hot'])

# Create interaction features
df['temp_humidity_interaction'] = df['temp_c'] * df['humidity_pct']

# Create lagged weather features
for lag in [1, 3, 6, 12]:
    df[f'temp_lag_{lag}'] = df['temp_c'].shift(lag)</pre>
                        </div>
                        
                        <p><strong>Why:</strong> Energy consumption for heating and cooling is highly dependent on temperature. Binning captures nonlinear relationships, and interaction features account for combined effects (e.g., high humidity makes hot temperatures feel warmer).</p>
                    </div>
                    
                    <h3>4.C Data Normalization & Sequence Generation</h3>
                    <p><strong>Goal:</strong> Normalize features and create sequences suitable for LSTM input.</p>
                    
                    <div class="step-box">
                        <h4>1) Feature normalization</h4>
                        <p><strong>Transform:</strong></p>
                        <div class="code-block">
                            <pre>from sklearn.preprocessing import MinMaxScaler

# Select features to normalize
features_to_normalize = ['consumption_kwh', 'temp_c', 'humidity_pct', 'wind_speed_kmh',
                         'consumption_lag_1', 'consumption_lag_24', 'temp_lag_1']

# Initialize scaler
scaler = MinMaxScaler(feature_range=(0, 1))

# Fit and transform
df[features_to_normalize] = scaler.fit_transform(df[features_to_normalize])</pre>
                        </div>
                        
                        <p><strong>Why:</strong> LSTMs are sensitive to the scale of input features. Normalization ensures all features contribute equally to the model and helps with faster convergence during training.</p>
                    </div>
                    
                    <div class="step-box">
                        <h4>2) Sequence generation</h4>
                        <p><strong>Transform:</strong></p>
                        <div class="code-block">
                            <pre>def create_sequences(data, sequence_length, target_column):
    """Create sequences for LSTM training"""
    sequences = []
    targets = []
    
    for i in range(len(data) - sequence_length):
        sequences.append(data.iloc[i:i+sequence_length].values)
        targets.append(data.iloc[i+sequence_length][target_column])
    
    return np.array(sequences), np.array(targets)

# Define sequence length (e.g., 24 hours of data)
sequence_length = 24

# Create sequences
X, y = create_sequences(df, sequence_length, 'consumption_kwh')

# Split into train and test sets
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]</pre>
                        </div>
                        
                        <p><strong>Why:</strong> LSTMs require input data in the form of sequences. Each sequence contains historical data (features) that the model uses to predict the target value at the next time step.</p>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="tab-content" id="models">
            <div class="card">
                <div class="card-header">
                    <i class="fas fa-brain"></i>
                    <h2>Model Details</h2>
                    <span class="badge">Deep Dive</span>
                </div>
                <div class="card-body">
                    <h3>LSTM Architecture</h3>
                    <p>Our LSTM model is designed to capture both short-term and long-term dependencies in energy consumption data:</p>
                    
                    <div class="step-box">
                        <h4>1) Model Architecture</h4>
                        <div class="code-block">
                            <pre>from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization
from tensorflow.keras.regularizers import l2

# Define model
model = Sequential()

# First LSTM layer with return sequences for stacking
model.add(LSTM(units=100, return_sequences=True, 
               input_shape=(X_train.shape[1], X_train.shape[2]),
               kernel_regularizer=l2(0.01)))
model.add(Dropout(0.2))
model.add(BatchNormalization())

# Second LSTM layer
model.add(LSTM(units=80, return_sequences=False, kernel_regularizer=l2(0.01)))
model.add(Dropout(0.2))
model.add(BatchNormalization())

# Dense layers
model.add(Dense(units=50, activation='relu'))
model.add(Dropout(0.1))

# Output layer
model.add(Dense(units=1))

# Compile model
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Model summary
model.summary()</pre>
                        </div>
                        
                        <p><strong>Why this architecture:</strong></p>
                        <ul>
                            <li>Stacked LSTM layers capture hierarchical temporal patterns</li>
                            <li>Dropout and L2 regularization prevent overfitting</li>
                            <li>Batch normalization stabilizes training</li>
                            <li>Dense layers learn nonlinear combinations of LSTM outputs</li>
                        </ul>
                    </div>
                    
                    <div class="step-box">
                        <h4>2) LSTM Cell Mechanics</h4>
                        <p>LSTM cells contain three gates that control information flow:</p>
                        <div class="formula">
                            forget gate: f<sub>t</sub> = σ(W<sub>f</sub> · [h<sub>t-1</sub>, x<sub>t</sub>] + b<sub>f</sub>)<br>
                            input gate: i<sub>t</sub> = σ(W<sub>i</sub> · [h<sub>t-1</sub>, x<sub>t</sub>] + b<sub>i</sub>)<br>
                            output gate: o<sub>t</sub> = σ(W<sub>o</sub> · [h<sub>t-1</sub>, x<sub>t</sub>] + b<sub>o</sub>)<br>
                            cell state: C̃<sub>t</sub> = tanh(W<sub>C</sub> · [h<sub>t-1</sub>, x<sub>t</sub>] + b<sub>C</sub>)<br>
                            memory cell: C<sub>t</sub> = f<sub>t</sub> ⊙ C<sub>t-1</sub> + i<sub>t</sub> ⊙ C̃<sub>t</sub><br>
                            hidden state: h<sub>t</sub> = o<sub>t</sub> ⊙ tanh(C<sub>t</sub>)
                        </div>
                        
                        <p><strong>How it works for energy forecasting:</strong></p>
                        <ul>
                            <li><strong>Forget gate:</strong> Decides what information to discard from previous time steps (e.g., forget consumption patterns from several days ago)</li>
                            <li><strong>Input gate:</strong> Decides what new information to store (e.g., remember that it's a hot day)</li>
                            <li><strong>Output gate:</strong> Decides what to output based on memory cell state (e.g., output high consumption prediction)</li>
                        </ul>
                    </div>
                    
                    <div class="step-box">
                        <h4>3) Training Process</h4>
                        <div class="code-block">
                            <pre>from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

# Define callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)

# Train model
history = model.fit(
    X_train, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.2,
    callbacks=[early_stopping, model_checkpoint, reduce_lr],
    verbose=1
)</pre>
                        </div>
                        
                        <p><strong>Training strategy:</strong></p>
                        <ul>
                            <li>Early stopping prevents overfitting by monitoring validation loss</li>
                            <li>Model checkpoint saves the best model during training</li>
                            <li>Learning rate reduction adjusts training when improvement stalls</li>
                            <li>Batch size of 32 provides a good balance between speed and stability</li>
                        </ul>
                    </div>
                    
                    <h3>Ensemble with Traditional Models</h3>
                    <p>To improve robustness, we combine LSTM predictions with those from traditional time series models:</p>
                    
                    <div class="step-box">
                        <h4>1) ARIMA Model</h4>
                        <div class="code-block">
                            <pre>from statsmodels.tsa.arima.model import ARIMA

# Fit ARIMA model
arima_model = ARIMA(train_data['consumption_kwh'], order=(5, 1, 2))
arima_result = arima_model.fit()

# Generate forecasts
arima_forecast = arima_result.forecast(steps=len(test_data))</pre>
                        </div>
                    </div>
                    
                    <div class="step-box">
                        <h4>2) Prophet Model</h4>
                        <div class="code-block">
                            <pre>from prophet import Prophet

# Prepare data for Prophet
prophet_data = train_data.reset_index()
prophet_data.columns = ['ds', 'y']

# Fit Prophet model
prophet_model = Prophet(
    yearly_seasonality=True,
    weekly_seasonality=True,
    daily_seasonality=True,
    holidays=holidays_df
)
prophet_model.add_regressor('temp_c')
prophet_model.add_regressor('is_holiday')
prophet_model.fit(prophet_data)

# Generate forecasts
future = prophet_model.make_future_dataframe(periods=len(test_data), freq='H')
future = future.merge(test_data[['temp_c', 'is_holiday']], left_on='ds', right_index=True, how='left')
prophet_forecast = prophet_model.predict(future)</pre>
                        </div>
                    </div>
                    
                    <div class="step-box">
                        <h4>3) Ensemble Predictions</h4>
                        <div class="code-block">
                            <pre># Generate LSTM predictions
lstm_predictions = model.predict(X_test)

# Inverse transform predictions
lstm_predictions = scaler.inverse_transform(
    np.concatenate([lstm_predictions, np.zeros((len(lstm_predictions), len(features_to_normalize)-1))], axis=1)
)[:, 0]

# Simple weighted average ensemble
ensemble_predictions = (
    0.5 * lstm_predictions +
    0.3 * arima_forecast.values +
    0.2 * prophet_forecast['yhat'].values[-len(test_data):]
)</pre>
                        </div>
                        
                        <p><strong>Why ensemble:</strong></p>
                        <ul>
                            <li>LSTM captures complex nonlinear patterns</li>
                            <li>ARIMA models linear autocorrelations well</li>
                            <li>Prophet handles seasonality and holidays explicitly</li>
                            <li>Combining models reduces variance and improves generalization</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="tab-content" id="evaluation">
            <div class="card">
                <div class="card-header">
                    <i class="fas fa-chart-line"></i>
                    <h2>Evaluation & Metrics</h2>
                    <span class="badge">Performance</span>
                </div>
                <div class="card-body">
                    <h3>Forecast Evaluation Metrics</h3>
                    <p>We use multiple metrics to evaluate the performance of our energy consumption forecasts:</p>
                    
                    <div class="step-box">
                        <h4>1) Regression Metrics</h4>
                        <div class="code-block">
                            <pre>from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Calculate metrics
mae = mean_absolute_error(y_true, y_pred)
mse = mean_squared_error(y_true, y_pred)
rmse = np.sqrt(mse)
mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
r2 = r2_score(y_true, y_pred)

print(f"MAE: {mae:.4f}")
print(f"MSE: {mse:.4f}")
print(f"RMSE: {rmse:.4f}")
print(f"MAPE: {mape:.4f}%")
print(f"R²: {r2:.4f}")</pre>
                        </div>
                        
                        <p><strong>Interpretation:</strong></p>
                        <ul>
                            <li><strong>MAE (Mean Absolute Error):</strong> Average absolute difference between predicted and actual values. Easy to interpret in the original units (kWh).</li>
                            <li><strong>RMSE (Root Mean Squared Error):</strong> Similar to MAE but penalizes larger errors more heavily.</li>
                            <li><strong>MAPE (Mean Absolute Percentage Error):</strong> Percentage error, useful for comparing across different scales.</li>
                            <li><strong>R² (Coefficient of Determination):</strong> Proportion of variance in the target variable that is explained by the model.</li>
                        </ul>
                    </div>
                    
                    <div class="step-box">
                        <h4>2) Time Series Specific Metrics</h4>
                        <div class="code-block">
                            <pre>def mase(y_true, y_pred, y_train, seasonality=24):
    """Mean Absolute Scaled Error"""
    # Calculate MAE of predictions
    mae_pred = np.mean(np.abs(y_true - y_pred))
    
    # Calculate MAE of naive seasonal forecast on training data
    mae_naive = np.mean(np.abs(y_train[seasonality:] - y_train[:-seasonality]))
    
    return mae_pred / mae_naive

def smape(y_true, y_pred):
    """Symmetric Mean Absolute Percentage Error"""
    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2
    diff = np.abs(y_true - y_pred) / denominator
    diff[denominator == 0] = 0.0
    return 100 * np.mean(diff)

# Calculate metrics
mase_value = mase(y_true, y_pred, y_train)
smape_value = smape(y_true, y_pred)

print(f"MASE: {mase_value:.4f}")
print(f"sMAPE: {smape_value:.4f}%")</pre>
                        </div>
                        
                        <p><strong>Why these metrics:</strong></p>
                        <ul>
                            <li><strong>MASE (Mean Absolute Scaled Error):</strong> Compares forecast accuracy against a naive seasonal forecast. Values less than 1 indicate better performance than the naive approach.</li>
                            <li><strong>sMAPE (Symmetric Mean Absolute Percentage Error):</strong> Addresses some limitations of MAPE, especially when actual values are close to zero.</li>
                        </ul>
                    </div>
                    
                    <h3>Visual Evaluation</h3>
                    <p>Visual inspection of forecasts is crucial for understanding model performance:</p>
                    
                    <div class="step-box">
                        <h4>1) Forecast vs Actual Plot</h4>
                        <div class="code-block">
                            <pre>import matplotlib.pyplot as plt

plt.figure(figsize=(15, 6))
plt.plot(test_dates, y_true, label='Actual', color='blue')
plt.plot(test_dates, y_pred, label='Forecast', color='red', linestyle='--')
plt.fill_between(test_dates, lower_bound, upper_bound, color='red', alpha=0.1, label='95% Confidence Interval')
plt.title('Energy Consumption Forecast vs Actual')
plt.xlabel('Date')
plt.ylabel('Consumption (kWh)')
plt.legend()
plt.grid(True)
plt.show()</pre>
                        </div>
                        
                        <p>This plot helps visualize how well the forecast captures the actual consumption patterns, including peaks and valleys.</p>
                    </div>
                    
                    <div class="step-box">
                        <h4>2) Residual Analysis</h4>
                        <div class="code-block">
                            <pre># Calculate residuals
residuals = y_true - y_pred

# Plot residuals
plt.figure(figsize=(15, 6))
plt.subplot(2, 1, 1)
plt.plot(test_dates, residuals)
plt.axhline(y=0, color='r', linestyle='-')
plt.title('Residuals Over Time')
plt.xlabel('Date')
plt.ylabel('Residuals')

plt.subplot(2, 1, 2)
plt.hist(residuals, bins=30)
plt.title('Residuals Distribution')
plt.xlabel('Residual Value')
plt.ylabel('Frequency')

plt.tight_layout()
plt.show()</pre>
                        </div>
                        
                        <p><strong>What to look for:</strong></p>
                        <ul>
                            <li>Residuals should be randomly distributed around zero (no patterns)</li>
                            <li>Residuals should follow a normal distribution</li>
                            <li>No autocorrelation in residuals (no remaining patterns to capture)</li>
                        </ul>
                    </div>
                    
                    <h3>Operational Metrics</h3>
                    <p>Beyond statistical metrics, we evaluate the business impact of our forecasts:</p>
                    
                    <div class="step-box">
                        <h4>1) Peak Detection Accuracy</h4>
                        <div class="code-block">
                            <pre># Define peak threshold (e.g., top 10% of consumption)
peak_threshold = np.percentile(y_train, 90)

# Identify actual and predicted peaks
actual_peaks = y_true > peak_threshold
predicted_peaks = y_pred > peak_threshold

# Calculate precision and recall
true_positives = np.sum(actual_peaks & predicted_peaks)
false_positives = np.sum(~actual_peaks & predicted_peaks)
false_negatives = np.sum(actual_peaks & ~predicted_peaks)

precision = true_positives / (true_positives + false_positives)
recall = true_positives / (true_positives + false_negatives)
f1_score = 2 * (precision * recall) / (precision + recall)

print(f"Peak Detection Precision: {precision:.4f}")
print(f"Peak Detection Recall: {recall:.4f}")
print(f"Peak Detection F1 Score: {f1_score:.4f}")</pre>
                        </div>
                        
                        <p><strong>Why important:</strong> Accurately predicting peak consumption periods is critical for grid stability and optimizing energy generation costs.</p>
                    </div>
                    
                    <div class="step-box">
                        <h4>2) Cost Savings Analysis</h4>
                        <div class="code-block">
                            <pre># Calculate cost of energy procurement
def calculate_procurement_cost(actual_demand, forecast_demand, base_price, peak_price):
    """Calculate energy procurement cost based on forecast"""
    # Base cost (assuming perfect forecast)
    base_cost = np.sum(actual_demand * base_price)
    
    # Actual cost with forecast errors
    # If forecast is below actual, need to purchase at peak price
    shortfall = np.maximum(0, actual_demand - forecast_demand)
    peak_cost = np.sum(shortfall * peak_price)
    
    # Regular cost for accurately forecasted demand
    regular_cost = np.sum(np.minimum(actual_demand, forecast_demand) * base_price)
    
    total_cost = regular_cost + peak_cost
    
    # Savings compared to naive forecast (using yesterday's values)
    naive_forecast = np.roll(actual_demand, 24)
    naive_shortfall = np.maximum(0, actual_demand - naive_forecast)
    naive_peak_cost = np.sum(naive_shortfall * peak_price)
    naive_regular_cost = np.sum(np.minimum(actual_demand, naive_forecast) * base_price)
    naive_total_cost = naive_regular_cost + naive_peak_cost
    
    savings = naive_total_cost - total_cost
    savings_pct = (savings / naive_total_cost) * 100
    
    return total_cost, savings, savings_pct

# Example usage
base_price = 0.12  # $ per kWh
peak_price = 0.25  # $ per kWh

total_cost, savings, savings_pct = calculate_procurement_cost(
    y_true, y_pred, base_price, peak_price
)

print(f"Total Procurement Cost: ${total_cost:.2f}")
print(f"Savings vs Naive Forecast: ${savings:.2f} ({savings_pct:.2f}%)")</pre>
                        </div>
                        
                        <p><strong>Why important:</strong> This metric quantifies the direct financial impact of improved forecasting on energy procurement costs.</p>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="tab-content" id="implementation">
            <div class="card">
                <div class="card-header">
                    <i class="fas fa-cogs"></i>
                    <h2>Implementation & Operations</h2>
                    <span class="badge">Production</span>
                </div>
                <div class="card-body">
                    <h3>Deployment Strategy</h3>
                    <p>Our forecasting system is deployed using a hybrid batch/real-time architecture:</p>
                    
                    <div class="step-box">
                        <h4>1) Batch Forecasting Pipeline</h4>
                        <div class="code-block">
                            <pre># Daily batch forecasting job
def daily_forecast_job():
    """Run daily energy consumption forecasting"""
    # 1. Data ingestion
    energy_data = fetch_energy_data(days_back=90)
    weather_data = fetch_weather_forecast(days_ahead=7)
    calendar_data = fetch_calendar_data()
    
    # 2. Data preprocessing
    processed_data = preprocess_data(energy_data, weather_data, calendar_data)
    
    # 3. Feature engineering
    featured_data = engineer_features(processed_data)
    
    # 4. Generate forecasts
    lstm_forecast = generate_lstm_forecast(featured_data)
    arima_forecast = generate_arima_forecast(featured_data)
    prophet_forecast = generate_prophet_forecast(featured_data)
    
    # 5. Ensemble forecasts
    ensemble_forecast = ensemble_forecasts(
        lstm_forecast, arima_forecast, prophet_forecast,
        weights=[0.5, 0.3, 0.2]
    )
    
    # 6. Calculate prediction intervals
    lower_bound, upper_bound = calculate_prediction_intervals(ensemble_forecast)
    
    # 7. Store forecasts
    store_forecasts(ensemble_forecast, lower_bound, upper_bound)
    
    # 8. Generate alerts for anomalous forecasts
    generate_anomaly_alerts(ensemble_forecast)
    
    return ensemble_forecast</pre>
                        </div>
                        
                        <p><strong>Batch schedule:</strong></p>
                        <ul>
                            <li>Daily at 2:00 AM (after all daily data is available)</li>
                            <li>Generates 7-day ahead forecasts</li>
                            <li>Updates customer-facing applications and internal systems</li>
                        </ul>
                    </div>
                    
                    <div class="step-box">
                        <h4>2) Real-time Forecast Adjustment</h4>
                        <div class="code-block">
                            <pre># Real-time forecast adjustment API
@app.route('/api/forecast/adjust', methods=['POST'])
def adjust_forecast():
    """Adjust forecasts based on real-time data"""
    # Get latest data
    latest_data = request.json
    
    # Load pre-trained model
    model = load_model('lstm_model.h5')
    
    # Preprocess latest data
    processed_data = preprocess_realtime_data(latest_data)
    
    # Create sequence from latest data
    sequence = create_sequence_from_latest(processed_data)
    
    # Generate short-term forecast (next 6 hours)
    short_term_forecast = model.predict(sequence)
    
    # Adjust daily batch forecast with real-time prediction
    adjusted_forecast = adjust_batch_forecast(short_term_forecast)
    
    # Return adjusted forecast
    return jsonify({
        'forecast': adjusted_forecast.tolist(),
        'timestamp': datetime.now().isoformat()
    })</pre>
                        </div>
                        
                        <p><strong>Real-time triggers:</strong></p>
                        <ul>
                            <li>Extreme weather events</li>
                            <li>Unexpected grid disruptions</li>
                            <li>Special events not in calendar</li>
                        </ul>
                    </div>
                    
                    <h3>Monitoring & Maintenance</h3>
                    <p>Continuous monitoring ensures the forecasting system remains accurate and reliable:</p>
                    
                    <div class="step-box">
                        <h4>1) Model Performance Monitoring</h4>
                        <div class="code-block">
                            <pre># Daily model performance check
def check_model_performance():
    """Check if model performance has degraded"""
    # Get recent forecasts and actuals
    recent_forecasts = fetch_recent_forecasts(days=7)
    recent_actuals = fetch_recent_actuals(days=7)
    
    # Calculate metrics
    mae = mean_absolute_error(recent_actuals, recent_forecasts)
    mape = calculate_mape(recent_actuals, recent_forecasts)
    
    # Compare with baseline
    baseline_mae = get_baseline_metric('mae')
    baseline_mape = get_baseline_metric('mape')
    
    # Check for degradation
    if mae > baseline_mae * 1.2 or mape > baseline_mape * 1.2:
        # Alert for model degradation
        send_alert(
            subject="Model Performance Degradation",
            message=f"MAE: {mae:.4f} (baseline: {baseline_mae:.4f}), MAPE: {mape:.4f}% (baseline: {baseline_mape:.4f}%)"
        )
        
        # Trigger model retraining
        trigger_retraining()
    
    # Update baseline metrics
    update_baseline_metrics({'mae': mae, 'mape': mape})</pre>
                        </div>
                        
                        <p><strong>Performance thresholds:</strong></p>
                        <ul>
                            <li>Alert if MAE increases by more than 20% from baseline</li>
                            <li>Alert if MAPE increases by more than 20% from baseline</li>
                            <li>Automatic retraining triggered if alerts persist for 3 consecutive days</li>
                        </ul>
                    </div>
                    
                    <div class="step-box">
                        <h4>2) Data Drift Detection</h4>
                        <div class="code-block">
                            <pre>def detect_data_drift():
    """Detect drift in input data distribution"""
    # Get recent and reference data
    recent_data = fetch_recent_data(days=30)
    reference_data = fetch_reference_data()  # Training data
    
    # Calculate statistical distances
    for feature in numerical_features:
        # Kolmogorov-Smirnov test
        ks_stat, ks_pvalue = ks_2samp(
            recent_data[feature], 
            reference_data[feature]
        )
        
        # Population Stability Index (PSI)
        psi = calculate_psi(
            reference_data[feature], 
            recent_data[feature]
        )
        
        # Check for significant drift
        if ks_pvalue < 0.05 or psi > 0.1:
            send_alert(
                subject="Data Drift Detected",
                message=f"Feature: {feature}, KS p-value: {ks_pvalue:.4f}, PSI: {psi:.4f}"
            )
            
            # Trigger model retraining
            trigger_retraining()
    
    # Check categorical features
    for feature in categorical_features:
        # Chi-squared test
        chi2_stat, chi2_pvalue, _, _ = chi2_contingency(
            pd.crosstab(
                recent_data[feature], 
                reference_data[feature]
            )
        )
        
        if chi2_pvalue < 0.05:
            send_alert(
                subject="Data Drift Detected",
                message=f"Categorical feature: {feature}, Chi2 p-value: {chi2_pvalue:.4f}"
            )
            
            # Trigger model retraining
            trigger_retraining()</pre>
                        </div>
                        
                        <p><strong>Drift detection methods:</strong></p>
                        <ul>
                            <li>Kolmogorov-Smirnov test for numerical features</li>
                            <li>Population Stability Index (PSI) for numerical features</li>
                            <li>Chi-squared test for categorical features</li>
                        </ul>
                    </div>
                    
                    <h3>Retraining Strategy</h3>
                    <p>Models are retrained regularly to maintain accuracy as patterns evolve:</p>
                    
                    <div class="step-box">
                        <h4>1) Scheduled Retraining</h4>
                        <div class="code-block">
                            <pre># Monthly model retraining
def monthly_retraining():
    """Retrain models with latest data"""
    # Fetch extended training data
    training_data = fetch_training_data(months=12)
    
    # Split into train and validation sets
    train_data, val_data = time_series_split(training_data, test_size=0.2)
    
    # Retrain LSTM model
    lstm_model = retrain_lstm_model(train_data, val_data)
    
    # Retrain ARIMA model
    arima_model = retrain_arima_model(train_data)
    
    # Retrain Prophet model
    prophet_model = retrain_prophet_model(train_data)
    
    # Evaluate new models
    lstm_metrics = evaluate_model(lstm_model, val_data)
    arima_metrics = evaluate_model(arima_model, val_data)
    prophet_metrics = evaluate_model(prophet_model, val_data)
    
    # Update ensemble weights based on performance
    new_weights = optimize_ensemble_weights(
        [lstm_metrics, arima_metrics, prophet_metrics]
    )
    
    # Deploy new models
    deploy_models(lstm_model, arima_model, prophet_model, new_weights)
    
    # Log retraining event
    log_retraining_event(
        models=['LSTM', 'ARIMA', 'Prophet'],
        metrics=[lstm_metrics, arima_metrics, prophet_metrics],
        weights=new_weights
    )</pre>
                        </div>
                        
                        <p><strong>Retraining schedule:</strong></p>
                        <ul>
                            <li>Monthly full retraining with all available data</li>
                            <li>Quarterly hyperparameter tuning</li>
                            <li>On-demand retraining triggered by performance degradation or data drift</li>
                        </ul>
                    </div>
                    
                    <h3>Business Integration</h3>
                    <p>Forecasts are integrated with various business systems:</p>
                    
                    <div class="step-box">
                        <h4>1) Energy Management System Integration</h4>
                        <div class="code-block">
                            <pre># Integration with energy management system
def integrate_with_energy_management():
    """Push forecasts to energy management system"""
    # Fetch latest forecasts
    forecasts = fetch_latest_forecasts()
    
    # Format for energy management system
    formatted_forecasts = []
    for forecast in forecasts:
        formatted_forecasts.append({
            'timestamp': forecast['timestamp'],
            'predicted_demand': forecast['value'],
            'lower_bound': forecast['lower_bound'],
            'upper_bound': forecast['upper_bound'],
            'confidence': forecast['confidence']
        })
    
    # Push to energy management system API
    response = requests.post(
        'https://energy-management-api.example.com/forecasts',
        json=formatted_forecasts,
        headers={'Authorization': f'Bearer {get_api_token()}'}
    )
    
    if response.status_code == 200:
        log_success("Forecasts pushed to energy management system")
    else:
        log_error(f"Failed to push forecasts: {response.text}")</pre>
                        </div>
                    </div>
                    
                    <div class="step-box">
                        <h4>2) Customer-facing Application Integration</h4>
                        <div class="code-block">
                            <pre># Integration with customer portal
def update_customer_portal():
    """Update customer portal with personalized insights"""
    # Fetch customer forecasts and insights
    customer_data = fetch_customer_forecasts()
    
    # Generate personalized insights
    for customer in customer_data:
        # Calculate usage patterns
        usage_patterns = analyze_usage_patterns(customer['history'])
        
        # Generate recommendations
        recommendations = generate_recommendations(
            usage_patterns, 
            customer['forecast'],
            customer['tariff']
        )
        
        # Calculate potential savings
        potential_savings = calculate_potential_savings(
            customer['history'],
            recommendations
        )
        
        # Update customer portal
        update_customer_record(
            customer_id=customer['id'],
            data={
                'forecast': customer['forecast'],
                'insights': usage_patterns,
                'recommendations': recommendations,
                'potential_savings': potential_savings
            }
        )
        
        # Send notification if significant savings opportunity
        if potential_savings > 10:  # $10 threshold
            send_customer_notification(
                customer_id=customer['id'],
                message=f"You could save ${potential_savings:.2f} on your next energy bill!",
                type='savings_opportunity'
            )</pre>
                        </div>
                        
                        <p><strong>Customer benefits:</strong></p>
                        <ul>
                            <li>Personalized energy usage insights</li>
                            <li>Cost-saving recommendations</li>
                            <li>Alerts for unusual consumption patterns</li>
                        </ul>
                    </div>
                    
                    <h3>Summary of Implementation</h3>
                    <ul>
                        <li><strong>Hybrid architecture:</strong> Combines batch forecasting for long-term planning with real-time adjustments for immediate needs</li>
                        <li><strong>Comprehensive monitoring:</strong> Tracks model performance and data drift to maintain accuracy</li>
                        <li><strong>Regular retraining:</strong> Scheduled and on-demand retraining ensures models adapt to changing patterns</li>
                        <li><strong>Business integration:</strong> Forecasts drive operational decisions and customer engagement</li>
                    </ul>
                </div>
            </div>
        </div>
        
        <div class="footer">
            <p>© 2025 Time-Series Forecasting with LSTM: Energy Consumption Predictions Documentation</p>
        </div>
    </div>
    
    <script>
        // Tab functionality
        document.addEventListener('DOMContentLoaded', function() {
            const tabs = document.querySelectorAll('.nav-tab');
            const tabContents = document.querySelectorAll('.tab-content');
            
            tabs.forEach(tab => {
                tab.addEventListener('click', () => {
                    const tabId = tab.getAttribute('data-tab');
                    
                    // Remove active class from all tabs and contents
                    tabs.forEach(t => t.classList.remove('active'));
                    tabContents.forEach(c => c.classList.remove('active'));
                    
                    // Add active class to clicked tab and corresponding content
                    tab.classList.add('active');
                    document.getElementById(tabId).classList.add('active');
                });
            });
        });
    </script>
</body>
</html>
